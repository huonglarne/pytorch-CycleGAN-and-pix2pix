[2023-07-07 19:32:41.992] [info] Requesting resources for KT AI Accelerator from the server...
[2023-07-07 19:32:43.007] [warning] A newer version of Moreh AI Framework is available. You can update the software to the latest version by running "update-moreh".
[2023-07-07 19:32:43.007] [info] Initializing the worker daemon for KT AI Accelerator
[2023-07-07 19:32:44.563] [info] [1/1] Connecting to resources on the server (192.168.110.8:24159)...
[2023-07-07 19:32:44.575] [info] Establishing links to the resources...
[2023-07-07 19:32:44.615] [info] KT AI Accelerator is ready to use.
Setting up a new session...
Warning: wandb package cannot be found. The option "--use_wandb" will result in error.
----------------- Options ---------------
               batch_size: 1                             
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 256                           
                 dataroot: ./datasets/facades            	[default: None]
             dataset_mode: aligned                       
                direction: BtoA                          	[default: AtoB]
              display_env: main                          
             display_freq: 400                           
               display_id: 1                             
            display_ncols: 4                             
             display_port: 8097                          
           display_server: http://localhost              
          display_winsize: 256                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: vanilla                       
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
                lambda_L1: 100.0                         
                load_iter: 0                             	[default: 0]
                load_size: 286                           
                       lr: 0.0002                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                    model: pix2pix                       	[default: cycle_gan]
                 n_epochs: 100                           
           n_epochs_decay: 100                           
               n_layers_D: 3                             
                     name: facades_pix2pix               	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_256                      
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                  no_html: False                         
                     norm: batch                         
              num_threads: 4                             
                output_nc: 3                             
                    phase: train                         
                pool_size: 0                             
               preprocess: resize_and_crop               
               print_freq: 100                           
             save_by_iter: False                         
          save_epoch_freq: 5                             
         save_latest_freq: 5000                          
           serial_batches: False                         
                   suffix:                               
         update_html_freq: 1000                          
                use_wandb: False                         
                  verbose: False                         
       wandb_project_name: CycleGAN-and-pix2pix          
----------------- End -------------------
dataset [AlignedDataset] was created
The number of training images = 400
initialize network with normal
initialize network with normal
model [Pix2PixModel] was created
---------- Networks initialized -------------
[Network G] Total number of parameters : 54.414 M
[Network D] Total number of parameters : 2.769 M
-----------------------------------------------
create web directory ./checkpoints/facades_pix2pix/web...
learning rate 0.0002000 -> 0.0002000
(epoch: 1, iters: 100, time: 0.213, data: 0.117) G_GAN: 1.022 G_L1: 31.069 D_real: 0.857 D_fake: 0.532 
(epoch: 1, iters: 200, time: 0.214, data: 0.002) G_GAN: 2.984 G_L1: 40.653 D_real: 0.048 D_fake: 0.204 
(epoch: 1, iters: 300, time: 0.211, data: 0.002) G_GAN: 2.353 G_L1: 30.875 D_real: 0.084 D_fake: 0.128 
(epoch: 1, iters: 400, time: 0.383, data: 0.002) G_GAN: 3.112 G_L1: 41.365 D_real: 0.144 D_fake: 0.100 
End of epoch 1 / 200 	 Time Taken: 66 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 2, iters: 100, time: 0.210, data: 0.120) G_GAN: 2.020 G_L1: 34.618 D_real: 0.232 D_fake: 0.071 
(epoch: 2, iters: 200, time: 0.209, data: 0.001) G_GAN: 2.200 G_L1: 33.110 D_real: 0.014 D_fake: 0.177 
(epoch: 2, iters: 300, time: 0.218, data: 0.002) G_GAN: 3.216 G_L1: 47.455 D_real: 0.021 D_fake: 0.056 
(epoch: 2, iters: 400, time: 0.363, data: 0.002) G_GAN: 2.668 G_L1: 38.860 D_real: 0.136 D_fake: 0.201 
End of epoch 2 / 200 	 Time Taken: 66 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 3, iters: 100, time: 0.210, data: 0.140) G_GAN: 3.233 G_L1: 35.440 D_real: 0.040 D_fake: 0.101 
(epoch: 3, iters: 200, time: 0.210, data: 0.001) G_GAN: 2.857 G_L1: 32.463 D_real: 0.294 D_fake: 0.041 
(epoch: 3, iters: 300, time: 0.212, data: 0.002) G_GAN: 5.049 G_L1: 37.429 D_real: 0.095 D_fake: 0.011 
(epoch: 3, iters: 400, time: 0.397, data: 0.002) G_GAN: 1.705 G_L1: 40.905 D_real: 0.002 D_fake: 1.938 
End of epoch 3 / 200 	 Time Taken: 66 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 4, iters: 100, time: 0.215, data: 0.120) G_GAN: 2.825 G_L1: 35.864 D_real: 0.018 D_fake: 1.830 
(epoch: 4, iters: 200, time: 0.211, data: 0.002) G_GAN: 2.674 G_L1: 39.594 D_real: 0.006 D_fake: 0.344 
(epoch: 4, iters: 300, time: 0.214, data: 0.002) G_GAN: 2.311 G_L1: 34.188 D_real: 0.041 D_fake: 0.997 
(epoch: 4, iters: 400, time: 0.408, data: 0.002) G_GAN: 2.740 G_L1: 32.666 D_real: 0.008 D_fake: 1.212 
End of epoch 4 / 200 	 Time Taken: 67 sec
learning rate 0.0002000 -> 0.0002000
(epoch: 5, iters: 100, time: 0.216, data: 0.145) G_GAN: 2.846 G_L1: 37.612 D_real: 0.035 D_fake: 0.398 
(epoch: 5, iters: 200, time: 0.211, data: 0.002) G_GAN: 3.346 G_L1: 35.595 D_real: 0.117 D_fake: 1.745 
(epoch: 5, iters: 300, time: 0.212, data: 0.002) G_GAN: 3.461 G_L1: 41.079 D_real: 0.002 D_fake: 1.971 
(epoch: 5, iters: 400, time: 0.427, data: 0.003) G_GAN: 1.649 G_L1: 27.048 D_real: 0.365 D_fake: 0.477 
saving the model at the end of epoch 5, iters 2000
End of epoch 5 / 200 	 Time Taken: 69 sec
learning rate 0.0002000 -> 0.0002000
[2023-07-07 19:38:21.538] [error] pydict_tensors, File "../frontend/execution.cpp", line 1974
Traceback (most recent call last):
  File "train.py", line 52, in <module>
    model.optimize_parameters()   # calculate loss functions, get gradients, update network weights
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/pix2pix_model.py", line 117, in optimize_parameters
    self.forward()                   # compute fake images: G(A)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/pix2pix_model.py", line 88, in forward
    self.fake_B = self.netG(self.real_A)  # G(A)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/wrapper/moreh_wrapper.py", line 132, in wrapper
    raise instance
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/wrapper/moreh_wrapper.py", line 73, in wrapper
    return moreh_function(
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/nn/parallel/data_parallel.py", line 25, in forward
    return self.module.forward(*inputs, **kwargs)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/networks.py", line 466, in forward
    return self.model(input)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/networks.py", line 534, in forward
    return self.model(x)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/networks.py", line 536, in forward
    return torch.cat([x, self.model(x)], 1)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/networks.py", line 536, in forward
    return torch.cat([x, self.model(x)], 1)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/networks.py", line 536, in forward
    return torch.cat([x, self.model(x)], 1)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/networks.py", line 536, in forward
    return torch.cat([x, self.model(x)], 1)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/networks.py", line 536, in forward
    return torch.cat([x, self.model(x)], 1)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/networks.py", line 536, in forward
    return torch.cat([x, self.model(x)], 1)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/huong/projects/pytorch-CycleGAN-and-pix2pix/models/networks.py", line 536, in forward
    return torch.cat([x, self.model(x)], 1)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/wrapper/moreh_wrapper.py", line 132, in wrapper
    raise instance
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/wrapper/moreh_wrapper.py", line 73, in wrapper
    return moreh_function(
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/nn/modules/activation.py", line 83, in forward
    return F.leaky_relu(input, self.negative_slope, self.inplace)
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/wrapper/moreh_wrapper.py", line 132, in wrapper
    raise instance
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/wrapper/moreh_wrapper.py", line 73, in wrapper
    return moreh_function(
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/nn/functional.py", line 2802, in leaky_relu
    return frontend.register_operation_([input], op)[0]
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/common/frontend.py", line 727, in register_operation_
    return _register_operation_internal(input_tensors, inplace_output_tensors,
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/torch/_M/driver/common/frontend.py", line 609, in _register_operation_internal
    output_tickets = moreh_f.create_operation(op_name, op.SerializeToString(),
  File "/nas/.conda/envs/hf/lib/python3.8/site-packages/moreh/driver/moreh_f/moreh_f.py", line 874, in create_operation
    return _moreh_f.create_operation(operator_str, proto_str_ptr, input_tickets, inplace_output_tickets, grad_enabled)
RuntimeError: pydict_tensors, File "../frontend/execution.cpp", line 1974
